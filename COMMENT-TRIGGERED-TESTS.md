# üí¨ Comment-Triggered Test Generation

## Overview

The AI Code Review Action now supports **comment-triggered test generation**! Instead of automatically generating tests on every PR, users can now request test generation on-demand by commenting on pull requests.

## How It Works

1. **User Comments**: Comment on any pull request with trigger phrases
2. **AI Analysis**: The action analyzes the changed files in the PR
3. **Test Generation**: AI generates comprehensive unit tests
4. **Comment Response**: Tests are posted as a comment with ready-to-use code
5. **Manual Integration**: Users copy and save the test code to their project

## Trigger Phrases

Comment any of these phrases on a pull request to trigger test generation:

- `write tests`
- `generate tests` 
- `/test`
- `create tests`

## Example Workflow

### 1. Comment on PR
```
User comments: "write tests"
```

### 2. AI Responds
```
ü§ñ AI Test Generator Results

‚úÖ Successfully generated 2 test file(s):

### üìÅ `src/utils/calculator.test.js`

<details>
<summary>View generated test code</summary>

```javascript
import { Calculator } from './calculator.js'

describe('Calculator', () => {
  let calculator

  beforeEach(() => {
    calculator = new Calculator()
  })

  describe('add', () => {
    it('should add two positive numbers correctly', () => {
      expect(calculator.add(2, 3)).toBe(5)
    })

    it('should handle negative numbers', () => {
      expect(calculator.add(-1, 1)).toBe(0)
    })
  })
})
```

</details>

---
*Generated by AI Test Generator. Copy the test code above and save it to the suggested file paths.*
```

### 3. User Copies and Saves
Users copy the generated test code and save it to their project.

## Features

- **Interactive**: Only generates tests when requested
- **Comprehensive**: Covers all changed files in the PR
- **Multi-Framework**: Supports Jest, pytest, JUnit, and more
- **Smart Filtering**: Excludes non-testable files
- **Ready-to-Use**: Generated code is properly formatted and structured
- **Customizable**: Uses custom test instructions if available

## Setup

### 1. Update Workflow

Add `issue_comment` trigger to your workflow:

```yaml
name: AI Code Review

on:
  pull_request:
    types: [opened, synchronize, reopened]
  issue_comment:
    types: [created]

permissions:
  contents: read
  pull-requests: write
  issues: write

jobs:
  ai-review:
    runs-on: ubuntu-latest
    name: AI Code Review

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: AI Code Review
        uses: your-username/ai-code-review@v1
        with:
          openai-api-key: ${{ secrets.OPENAI_API_KEY }}
          github-token: ${{ secrets.GITHUB_TOKEN }}
```

### 2. No Additional Configuration Needed

The feature works out of the box! No additional inputs or configuration required.

## Benefits

- **User Control**: Tests are only generated when needed
- **No Commit Pollution**: Tests don't automatically get committed
- **Review Before Use**: Users can review generated tests before integrating
- **Flexible**: Works with any existing PR workflow
- **Cost Effective**: Only uses OpenAI API when requested

## Supported Languages

| Language | Framework | Test File Pattern |
|----------|-----------|-------------------|
| JavaScript | Jest | `filename.test.js` |
| TypeScript | Jest | `filename.test.ts` |
| React JSX | Jest | `filename.test.jsx` |
| React TSX | Jest | `filename.test.tsx` |
| Python | pytest | `test_filename.py` |
| Java | JUnit | `filenameTest.java` |

## Custom Instructions

Create a `test-instructions.md` file in your repository root to customize test generation:

```markdown
# Test Generation Instructions

## Focus Areas
- Test all public methods and functions
- Include edge cases and error scenarios
- Mock external dependencies
- Use descriptive test names

## Custom Requirements
- Focus on testing authentication flows
- Ensure all database interactions are mocked
- Include performance tests for critical paths
```

## Migration from Automatic Generation

If you were using the automatic test generation feature (`generate-tests: true`), you can:

1. Remove the `generate-tests` input from your workflow
2. Add the `issue_comment` trigger
3. Users can now comment to generate tests on-demand

This provides much better control and prevents unwanted test file commits.
